# from openai import OpenAI

# # Kh·ªüi t·∫°o client
# client = OpenAI(api_key="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")

# # ƒê∆∞·ªùng d·∫´n file audio (ƒë·ªãnh d·∫°ng .mp3, .wav, .m4a, ...)
# audio_file = open("audio/au2.mp3", "rb")

# # G·ªçi API Whisper ƒë·ªÉ chuy·ªÉn ƒë·ªïi th√†nh vƒÉn b·∫£n
# transcript = client.audio.transcriptions.create(
#     model="whisper-1",
#     file=audio_file
# )

# print("K·∫øt qu·∫£ nh·∫≠n di·ªán gi·ªçng n√≥i:")
# print(transcript.text)

import sounddevice as sd
from scipy.io.wavfile import write
from openai import OpenAI

# C·∫•u h√¨nh
SAMPLE_RATE = 16000  # Whisper ho·∫°t ƒë·ªông t·ªët ·ªü 16kHz
DURATION = 5         # th·ªùi gian ghi √¢m (gi√¢y)

print("üé§ B·∫Øt ƒë·∫ßu ghi √¢m...")
recording = sd.rec(int(DURATION * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype="int16")
sd.wait()  # Ch·ªù ghi √¢m xong
print("‚úÖ Ghi √¢m xong!")

# L∆∞u file WAV t·∫°m
filename = "recorded_audio.wav"
write(filename, SAMPLE_RATE, recording)

# G·ªçi Whisper API
client = OpenAI(api_key="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")

with open(filename, "rb") as audio_file:
    transcript = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file
    )

print("üìù K·∫øt qu·∫£ nh·∫≠n di·ªán gi·ªçng n√≥i:")
print(transcript.text)

